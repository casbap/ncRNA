---
title: "DataPrep"
author: "Cas Baptist"
date: "3/7/2022"
output: html_document
---

### Introduction

set org = the organism you wish to test

The heirarchical clustering step needs a larger stack. Run this before executing:

`
ulimit -s 65533
`

### Prerequisite libraries

```{r Libraries, echo=TRUE}
suppressPackageStartupMessages({
    library(R.utils)
    library(dplyr)
    library(tidyr)
    library(data.table)
    library(RColorBrewer)
    library(gplots)
    library(edgeR)
    library(reshape2)
    library(Polychrome)
    library(dendextend)
    library(ggplot2)
    library(DESeq2)
    library(dynamicTreeCut)
    library(biomaRt)
    library(qdapTools)
    library(hrbrthemes)
    library(tibble)

})
source("functions.R")
```

### 1. Download and unzip the Human data 

```{r, Download Data, echo=TRUE}
# if statement checks if object exists
if ( !dir.exists("Data")) { dir.create("Data") }
if (!file.exists("Data/hsapiens_rand_se.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_se.tsv.bz2", 
              destfile = "Data/hsapiens_rand_se.tsv.bz2")}
if (!file.exists("Data/hsapiens_rand_se.tsv")){
    bunzip2("Data/hsapiens_rand_se.tsv.bz2", destname="Data/hsapiens_rand_se.tsv")}
orgData <- fread("Data/hsapiens_rand_se.tsv", sep = '\t', header = FALSE)
head(orgData)
```

### 2. Download, read, and unzip the QC data

```{r, QC Data, echo=TRUE}
if (!file.exists("hsapiens_rand_qc.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_qc.tsv.bz2", 
              destfile = "hsapiens_rand_qc.tsv.bz2")}
qcData <- fread("hsapiens_rand_qc.tsv.bz2", sep = '\t', 
  col.names = c("Database", "Description", "Details"))
head(qcData)
```

### 3. Filter and quantify databases according to qcSummary = PASS, WARN, or FAIL.  

```{r, QC Data Summary, echo=TRUE}
# Count the total number of qcSummary entries for checking
qcSummary <- qcData[qcData$Description == 'qcSummary',]
totalSummary <- nrow(qcSummary)
# Count the total number of databases marked as PASS
qcPass <- filter(qcData, grepl("PASS", Details))
totalPass <- nrow(qcPass)
# Count the total number of databases marked as WARN
qcWarn <- filter(qcData, grepl("WARN", Details))
totalWarn <- nrow(qcWarn)
# Count the total number of databases marked as FAIL
qcFail <- filter(qcData, grepl("FAIL", Details))
totalFail <- nrow(qcFail)
# Summary of counts. Addition of each PASS, WARN, and FAIL counts equals to total_summary.
qualitySummary <- data.frame(totalPass, totalWarn, totalFail, totalSummary)
qualitySummary
```

### 4. Select all the databases from org_se.tsv with qcSummary == 'PASS' 

```{r, Filter org bulk data, echo=TRUE}
# Filter all the sample names with qcSummary == 'PASS' from step 3
databasePass <- filter(qcData, grepl("PASS", Details)) 
# Convert the rows into string and store on a list to use for filtering org data
databasePassList <- as.character(databasePass$Database)
str(databasePassList)
# Filter org data using generated list
orgPass <- orgData[orgData$V1 %in% databasePassList,] 
# Convert format from long to wide
orgPassWide <- orgPass %>% pivot_wider(names_from = "V1", values_from = "V3")
# Convert tibble to data frame and assign column 1 as rowname
orgPassWide <- as.data.frame(orgPassWide)
rownames(orgPassWide) <- orgPassWide[,1]
orgPassWide <- orgPassWide[,-1]
orgPassWide[1:10,1:6]
saveRDS(orgPassWide, "orgPassWide.rds")
# Remove unneeded data
remove(orgPass)
remove(databasePass)
remove(qcSummary)
remove(totalSummary)
remove(qcWarn)
remove(totalWarn)
remove(qcFail)
remove(totalFail)
```

### 5. Aggregate multiple runs, if any, (SRR) to its corresponding experiment (SRX) with PASS only databases

```{r, SRR to SRX Aggregation, echo=TRUE}
# Download and read Metadata summary
if (!file.exists("hsapiens_metadata.tsv.cut")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_metadata.tsv.cut", 
              destfile = "hsapiens_metadata.tsv.cut")}
    
orgMetadata <- read.csv("hsapiens_metadata.tsv.cut", sep = '\t')
# Filter metadata to include only "passed" samples
orgMetadataPass <- orgMetadata[which(orgMetadata$SRR_accession %in% databasePassList),]
# Assign column 1 as rownames 
rownames(orgMetadataPass) <- orgMetadataPass[,1]
orgMetadataPass <- orgMetadataPass[,-1]
orgMetadataPass
saveRDS(orgMetadataPass, "orgMetadataPass.rds")
# Put the filtered org GeneCount data and the filtered metadata dataframes into a list
orgCountMetadata <- list(GeneCounts = orgPassWide, MetadataSummary = orgMetadataPass)
# Apply both dataframes to the function
head(orgCountMetadata)
agg <- srx_agg(orgCountMetadata)
# Remove genes with zero total counts 
length(which(rowSums(agg) == 0)) # 83
no_gene_counts <- names(which(rowSums(agg) == 0))
agg <- agg[!(rownames(agg) %in% no_gene_counts),]
# Save agg object
saveRDS(agg, "agg.rds")
# Histogram showing samples (columns) counts
hist(colSums(agg), breaks = 20)
# Remove unneeded data
remove(orgMetadata)
```

### 6. Normalisation of Data (with PASS only databases)

```{r, normalisation, echo=TRUE}
# Filtering low counts
# Check if there are genes with no counts (rowSums==0)
length(which(rowSums(agg) == 0)) # no rowSums = 0
#NORMALISATION FOR COMPOSITION BIAS (TMM normalisation)
dgeObj <- DGEList(agg)
# Apply TMM normalisation to DGEList object
dgeObj <- calcNormFactors(dgeObj, method = "TMM") 
normAgg <- cpm(dgeObj)
# Scale after normalisation
normAggScale <- scale(normAgg)
# Check distributions of samples
hist(normAggScale)
saveRDS(normAggScale,"normAggScale.rds")

# Correlation Matrix
# memory error - need to fix
correlate <- cor(t(normAggScale), method = "spearman")
correlate[upper.tri(correlate,diag=TRUE)] <- NA
correlate1 <- correlate[1:30000,]
correlate2 <- correlate[30001:nrow(correlate),]

correlate_melt1 <- reshape2::melt(correlate1, na.rm = TRUE)
correlate_melt2 <- reshape2::melt(correlate2, na.rm = TRUE)

correlate_melt <- rbind(correlate_melt1, correlate_melt2)
remove(correlate_melt1)
remove(correlate_melt2)

png("Data/hist_vds.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
hist(correlate, breaks = 20, xlab = "Gene Correlation Values", main = "Spearman Correlation of RNASeq Counts")
dev.off()

# Check for 0 values
length(which(correlate_melt$value ==0 )) # no zero values
```

### 7a. Hierarchical Clustering: linking method

There are different ways of deciding the distance of elements for them to be grouped into a cluster.The correlation between the distance matrix and the cophenetic distance is calculated to to ensure good
linkage method fit. 

```{r, hierarchical_clustering, echo=TRUE}
set.seed(42)
distClust <-as.dist(1-cor(t(normAggScale), method="spearman"))
hClust <- hclust(distClust , method="complete")
# Check the correlation between the distance 
# matrix and the cophenetic distance
cophenetic.d = cophenetic(hClust)
correlate_distClustVcoph <- cor(distClust, cophenetic.d)

#form dendogram
#ggplot(hClust, aes(A, B)) +
#  geom_point()
#ggsave("hClust.pdf")
#ggsave("hClust.png")

png("Data/dendro_Average.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
dend <- as.dendrogram(hClust)
#labels_colors(dend) <- "white"
plot(dend, main = paste0("Complete Method: Corr = ", signif(correlate_distClustVcoph)))
print(dend)
dev.off()
```

### 7a.2 Data Removal

Removes data functions for memory storage

```{r, data_removal1, echo=FALSE}
remove(cophenetic.d)
remove(correlate_distClustVcoph)
remove(dend)
```

### 7b. Heirarchical Clustering: deciding the number of clusters

A specific number of clusters can be set using the cutree function.

```{r, heirarchical1, echo=TRUE}
# Using the argument k in cutree is a faster process vs figuring out the cut height
cutClust <- cutree(hClust, k=200)
cutClustlength <- length(unique(cutClust))
# Cluster size
cutClustlength
# This is the base code used in the cl_lengthCut function below
clusters <- as.data.frame(cutClust)
colnames(clusters) <- "ClusterNumber"
clusters$ensembl_gene_id <- rownames(clusters)
  
```

### 8. Clustering genes using different cluster sizes 

This functions will will yield a list of genes grouped in cluster sized of 50 to 2000 to be 
used in downstream processes.

leave eval=FALSE, code runs with difficulty (requires manual cutHeight addition)



```{r, clustering1, eval=TRUE }
# Different Cluster sizes using the normal dendrogram cutree function
cutClustvalues <- cl_lengthCut(hr=hClust, min=50, max=2000, interval=2)
saveRDS(cutClustvalues, "cutClustvalues.rds")
# Different Cluster sizes using the dynamic method, cutreeHybrid from the dynamicTreeCut library
cutClustvalues_dynamic <- cl_cut_dynamic(hr=hClust, cl=distClust, min=4, max=302, interval=2)
saveRDS(cutClustvalues_dynamic, "cutClustvalues_dynamic.rds")

head(cutClustvalues_dynamic)
```


### 9. Heatmaps for the clusters

```{r, heatmaps1}
# Visualizations

if (!exists("P100")){
  P100 <- createPalette(100,  c("#ff0000", "#00ff00", "#0000ff"))}

clusterCols <- P100[1:100]
colfunc <- colorRampPalette(c("blue", "white", "red"))

# Heatmaps TMM
#png("Data/hm_TMM_sp.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
#cutClustusterSideBar <- clusterCols[normAggScale[["cutClust"]]]
#heatmap(correlate, main="Gene Correlation (TMM, Spearman)",  Rowv=as.dendrogram(hr),
#          dendrogram="both", scale="col", col = colfunc(25), trace="none",
#          RowSideColors= cutClustusterSideBar, margins = c(5,5))
#dev.off()
```

### Mem usage

```{r,memusage}
sort( sapply( ls() , function(x) { object.size( get( x ) ) }  )  )
```

### Session Information 

```{r Session Info, echo=FALSE}
sessionInfo()
```
