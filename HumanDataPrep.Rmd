---
title: "HumanDataPrep"
author: "Cas Baptist"
date: "3/7/2022"
output: html_document
---

### Introduction
set org = the organism you wish to test

### Prerequisite libraries

```{r Libraries, echo=TRUE}

suppressPackageStartupMessages({
    library(R.utils)
    library(dplyr)
    library(tidyr)
    library(data.table)
    library(RColorBrewer)
    library(gplots)
    library(edgeR)
    library(reshape2)
    library(Polychrome)
    library(dendextend)
    library(ggplot2)
    library(DESeq2)
    library(dynamicTreeCut)
})

source("functions.R")

```

### 1. Download and unzip the Human data 

```{r Download Data, echo=TRUE}

# if statement checks if object exists

if (!file.exists("Data/hsapiens_rand_se.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_se.tsv.bz2", 
              destfile = "Data/hsapiens_rand_se.tsv.bz2")}

if (!file.exists("Data/hsapiens_rand_se.tsv")){
    bunzip2("Data/hsapiens_rand_se.tsv.bz2", destname="Data/hsapiens_rand_se.tsv")}

orgData <- fread("Data/hsapiens_rand_se.tsv", sep = '\t', header = FALSE)

head(orgData)

```

### 2. Download, read, and unzip the QC data

```{r QC Data, echo=TRUE}

if (!file.exists("hsapiens_rand_qc.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_qc.tsv.bz2", 
              destfile = "hsapiens_rand_qc.tsv.bz2")}

qcData <- fread("hsapiens_rand_qc.tsv.bz2", sep = '\t', 
  col.names = c("Database", "Description", "Details"))

head(qcData)

```

### 3. Filter and quantify databases according to qcSummary = PASS, WARN, or FAIL.  

```{r QC Data Summary, echo=TRUE}

# Count the total number of qcSummary entries for checking
qcSummary <- qcData[qcData$Description == 'qcSummary',]
totalSummary <- nrow(qcSummary)

# Count the total number of databases marked as PASS
qcPass <- filter(qcData, grepl("PASS", Details))
totalPass <- nrow(qcPass)

# Count the total number of databases marked as WARN
qcWarn <- filter(qcData, grepl("WARN", Details))
totalWarn <- nrow(qcWarn)

# Count the total number of databases marked as FAIL
qcFail <- filter(qcData, grepl("FAIL", Details))
totalFail <- nrow(qcFail)

# Summary of counts. Addition of each PASS, WARN, and FAIL counts equals to total_summary.
qualitySummary <- data.frame(totalPass, totalWarn, totalFail, totalSummary)
qualitySummary

```

### 4. Select all the databases from org_se.tsv with qcSummary == 'PASS' 

```{r Filter org bulk data, echo=TRUE}

# Filter all the sample names with qcSummary == 'PASS' from step 3
databasePass <- filter(qcData, grepl("PASS", Details)) 

# Convert the rows into string and store on a list to use for filtering org data
databasePassList <- as.character(databasePass$Database)
str(databasePassList)

# Filter org data using generated list
orgPass <- orgData[orgData$V1 %in% databasePassList,] 

# Convert format from long to wide
orgPassWide <- orgPass %>% pivot_wider(names_from = "V1", values_from = "V3")

# Convert tibble to data frame and assign column 1 as rowname
orgPassWide <- as.data.frame(orgPassWide)
rownames(orgPassWide) <- orgPassWide[,1]
orgPassWide <- orgPassWide[,-1]

orgPassWide[1:10,1:6]

```

### 5. Aggregate multiple runs, if any, (SRR) to its corresponding experiment (SRX) with PASS only databases

```{r SRR to SRX Aggregation, echo=TRUE}

# Download and read Metadata summary

if (!file.exists("hsapiens_metadata.tsv.cut")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_metadata.tsv.cut", 
              destfile = "hsapiens_metadata.tsv.cut")}
    
orgMetadata <- read.csv("hsapiens_metadata.tsv.cut", sep = '\t')

# Filter metadata to include only "passed" samples
orgMetadataPass <- orgMetadata[which(orgMetadata$SRR_accession %in% databasePassList),]

# Assign column 1 as rownames 
rownames(orgMetadataPass) <- orgMetadataPass[,1]
orgMetadataPass <- orgMetadataPass[,-1]

# Put the filtered org GeneCount data and the filtered metadata dataframes into a list
orgCountMetadata <- list(GeneCounts = orgPassWide, MetadataSummary = orgMetadataPass)

# Apply both dataframes to the function
head(orgCountMetadata)
agg <- srx_agg(orgCountMetadata)

# Remove genes with zero total counts 
length(which(rowSums(agg) == 0)) # 83
no_gene_counts <- names(which(rowSums(agg) == 0))

agg <- agg[!(rownames(agg) %in% no_gene_counts),]

# Save agg object
saveRDS(agg, "agg.rds")

# Histogram showing samples (columns) counts
hist(colSums(agg), breaks = 20)

```

### 6. Normalisation of Data (with PASS only databases)

```{r echo=TRUE}

# Filtering low counts
# Check if there are genes with no counts (rowSums==0)
length(which(rowSums(agg) == 0)) # no rowSums = 0

#NORMALISATION FOR COMPOSITION BIAS (TMM normalisation)
dgeObj <- DGEList(agg)
# Apply TMM normalisation to DGEList object
dgeObj <- calcNormFactors(dgeObj, method = "TMM") 
normAgg <- cpm(dgeObj)

# Scale after normalisation
normAggScale <- scale(normAgg)

# Check distributions of samples
hist(normAggScale)
saveRDS(normAggScale,"normAggScale.rds")

# Correlation Matrix
## memory error - need to fix
#correlate <- cor(t(normAggScale), method = "spearman")
#correlate[upper.tri(correlate,diag=TRUE)] <- NA

#correlate_melt <- melt(correlate, na.rm = TRUE)

#png("Data/hist_vds.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
#hist(correlate, breaks = 20, xlab = "Gene Correlation Values", main = "Spearman Correlation of RNASeq Counts")
#dev.off()

# Check for 0 values
#length(which(correlate_melt$value ==0 )) # no zero values


```

### 7a. Hierarchical Clustering: linking method

There are different ways of deciding the distance of elements for them to be grouped into a cluster.The correlation between the distance matrix and the cophenetic distance is calculated to to ensure good
linkage method fit. 

```{r echo=TRUE}
set.seed(42)

distClust <-as.dist(1-cor(t(normAggScale), method="spearman"))
hClust <- hclust(distClust , method="complete")

# Check the correlation between the distance 
# matrix and the cophenetic distance
cophenetic.d = cophenetic(hClust)
correlate_distClustVcoph <- cor(distClust, cophenetic.d)

png("Data/dendro_Average.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
dend <- as.dendrogram(hClust)
labels_colors(dend) <- "white"
plot(dend, main = paste0("Complete Method: Corr = ", signif(correlate_distClustVcoph)))
dev.off()

```

### 7b. Heirarchical Clustering: deciding the number of clusters
A specific number of clusters can be set using the cutree function.

```{r echo=TRUE}

# Using the argument k in cutree is a faster process vs
# figuring out the cut height
  cutClust <- cutree(hClust, k=200)
  cutClustlength <- length(unique(cutClust))
# Cluster size
  cutClustlength
# This is the base code used in the cl_lengthCut function below
  clusters <- as.data.frame(cutClust)
  colnames(clusters) <- "ClusterNumber"
  clusters$GeneID <- rownames(clusters)
  

```

### 8. Clustering genes using different cluster sizes 

This functions will will yield a list of genes grouped in cluster sized of 50 to 2000 to be used in downstream processes.
#leave eval=FALSE, code runs with difficulty (requires manual cutHeight addition)

```{r eval=FALSE, include=FALSE}

# Different Cluster sizes using the normal dendrogram cutree function
cutClustvalues <- cl_lengthCut(hClust=hClust, min=50, max=2000, interval=2)
saveRDS(cutClustvalues, "cutClustvalues.rds")

# Different Cluster sizes using the dynamic method, cutreeHybrid from the dynamicTreeCut library
cutClustvalues_dynamic <- cl_cut_dynamic(hClust=hClust, distClust=distClust, min=4, max=302, interval=2)
saveRDS(cutClustvalues_dynamic, "cutClustvalues_dynamic.rds")

```


### 9. Heatmaps for the clusters
NOT WORKING
```{r eval=FALSE, include=FALSE}
# Visualizations
if (!exists("P100")){
  P100 <- createPalette(100,  c("#ff0000", "#00ff00", "#0000ff"))}

clusterCols <- P100[1:100]
colfunc <- colorRampPalette(c("blue", "white", "red"))

# Heatmaps TMM
png("Data/hm_TMM_sp.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
cutClustusterSideBar <- clusterCols[normAggCL_sp[["cutClust"]]]
heatmap.2(corr, main="Gene Correlation (TMM, Spearman)",  Rowv=as.dendrogram(hr),
          dendrogram="both", scale="col", col = colfunc(25), trace="none",
          RowSideColors= cutClustusterSideBar, margins = c(5,5))
dev.off()

```

### 10. Gene Ontology and Gene Data 

A binary matrix was constructed with the Entrez Gene IDs (NCBI gene IDs) as rownames and GO IDs as the column names (wide format). If a GO ID is associated with a Gene ID, the cell will equal to 1, otherwise it will be zero. 

```{r}

# Get the GO Annotation File (GAF) format 2.1 of org
if (!file.exists("Homo_sapiens.GRCh38.ncrna.fa.gz")){
    download.file("http://ftp.ensembl.org/pub/release-105/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz", 
              destfile = "Homo_sapiens.GRCh38.ncrna.fa.gz")}
if (!file.exists("Homo_sapiens.GRCh38.ncrna.fa.gz")){
    gunzip("Homo_sapiens.GRCh38.ncrna.fa.gz", destname="omo_sapiens.GRCh38.ncrna.fa.gz")}

orgGO <- fread("Homo_sapiens.GRCh38.ncrna.fa.gz", sep = '\t', header = FALSE)

# Subset unique GeneIDs (V11) and GO IDs (V5) in a dataframe. 
# Select the first gene synonym from column V11 and delete the rest. 
# Use this as the GeneID column. 
# Add another column with 1 in each row indicating the relationship of the Gene ID to the GO ID

orgGOmatrix <- data.frame(unique(orgGO[,c(11,5)]))
orgGOmatrix$GeneID <- gsub("\\|.*", "", orgGOmatrix$V11)
orgGOmatrix$V3 <- as.numeric(paste(1, orgGOmatrix$V3))
orgGOmatrix <- orgGOmatrix[,-1]

# Convert the dataframe to wide format with Gene ID as column 1 and GO ID as column names 
orgGOmatrixwide <- orgGOmatrix %>% pivot_wider(names_from = "V5", values_from = "V3")
orgGOmatrixwide <- as.data.frame(orgGOmatrixwide)
colnames(orgGOmatrixwide)[1] <- "GeneID"

# Convert NA to Zero
orgGOmatrixwide[is.na(orgGOmatrixwide)] <- 0

# Save the dataframe to an RDS file
saveRDS(orgGOmatrixwide, "orgGOmatrixwide.rds")

# GeneIDs that are in the gene count data but not in the GO matrix
diffCountGO <- setdiff(rownames(agg), orgGOmatrixwide$GeneID)

# GeneIDs that are in the GO matrix but not in the  gene count data
diffGOCount <- setdiff(orgGOmatrixwide$GeneID, rownames(agg))

# Remove the GeneIDs that are in the GO matrix but not in the gene count data
IndexRemoved <- which(orgGOmatrixwide$GeneID %in% diffGOCount)
GOtable <- orgGOmatrixwide
GOtable <- GOtable[-IndexRemoved,]
# Check if the genes were properly removed 
diffGOCount2 <- setdiff(GOtable$GeneID, rownames(agg))
dim(diffGOCount2)

# Save the new GO table
saveRDS(GOtable, "GOtable.rds")

```

### 11. Blind GO Terms (90-10 split)

10 per cent of GeneIDs will have zero Gene Ontology Annotations. This will serve as the training data. After the model has been optimised, these IDs will be unblided as the testing data.

```{r echo=TRUE}
#Fraction of the total number of genes to be blinded
test_size <- floor(0.10 * nrow(GOtable))

## set the seed to make your partition reproducible
set.seed(42)
blinded_ind <- sample(seq_len(nrow(GOtable)), size = test_size)
GOtrain <- GOtable
GOtrain[blinded_ind, 2:ncol(GOtrain)] = 0

saveRDS(GOtrain, "GOtrain.rds")

GO_test <- GOtable[blinded_ind,]
saveRDS(GO_test, "GO_test.rds")
normAggScale_test <- normAggScale[rownames(normAggScale) %in% GO_test$GeneID,]
saveRDS(normAggScale_test, "normAggScale_test.rds")

```


### Session Information 

```{r Session Info, echo=FALSE}

sessionInfo()

```