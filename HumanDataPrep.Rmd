---
title: "DataPrep"
author: "Cas Baptist"
date: "3/7/2022"
output: html_document
---

### Introduction

set org = the organism you wish to test

The heirarchical clustering step needs a larger stack. Run this before executing:

`
ulimit -s 65533
`

### Prerequisite libraries

```{r Libraries, echo=TRUE}

suppressPackageStartupMessages({
    library(R.utils)
    library(dplyr)
    library(tidyr)
    library(data.table)
    library(RColorBrewer)
    library(gplots)
    library(edgeR)
    library(reshape2)
    library(Polychrome)
    library(dendextend)
    library(ggplot2)
    library(DESeq2)
    library(dynamicTreeCut)
    library("biomaRt")
    library("qdapTools")
})

source("functions.R")

```

### 1. Download and unzip the Human data 

```{r, Download Data, echo=TRUE}

# if statement checks if object exists
if ( !dir.exists("Data")) { dir.create("Data") }


if (!file.exists("Data/hsapiens_rand_se.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_se.tsv.bz2", 
              destfile = "Data/hsapiens_rand_se.tsv.bz2")}

if (!file.exists("Data/hsapiens_rand_se.tsv")){
    bunzip2("Data/hsapiens_rand_se.tsv.bz2", destname="Data/hsapiens_rand_se.tsv")}

orgData <- fread("Data/hsapiens_rand_se.tsv", sep = '\t', header = FALSE)

head(orgData)

```

### 2. Download, read, and unzip the QC data

```{r, QC Data, echo=TRUE}

if (!file.exists("hsapiens_rand_qc.tsv.bz2")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_rand_qc.tsv.bz2", 
              destfile = "hsapiens_rand_qc.tsv.bz2")}

qcData <- fread("hsapiens_rand_qc.tsv.bz2", sep = '\t', 
  col.names = c("Database", "Description", "Details"))

head(qcData)

```

### 3. Filter and quantify databases according to qcSummary = PASS, WARN, or FAIL.  

```{r, QC Data Summary, echo=TRUE}

# Count the total number of qcSummary entries for checking
qcSummary <- qcData[qcData$Description == 'qcSummary',]
totalSummary <- nrow(qcSummary)

# Count the total number of databases marked as PASS
qcPass <- filter(qcData, grepl("PASS", Details))
totalPass <- nrow(qcPass)

# Count the total number of databases marked as WARN
qcWarn <- filter(qcData, grepl("WARN", Details))
totalWarn <- nrow(qcWarn)

# Count the total number of databases marked as FAIL
qcFail <- filter(qcData, grepl("FAIL", Details))
totalFail <- nrow(qcFail)

# Summary of counts. Addition of each PASS, WARN, and FAIL counts equals to total_summary.
qualitySummary <- data.frame(totalPass, totalWarn, totalFail, totalSummary)
qualitySummary

```

### 4. Select all the databases from org_se.tsv with qcSummary == 'PASS' 

```{r, Filter org bulk data, echo=TRUE}

# Filter all the sample names with qcSummary == 'PASS' from step 3
databasePass <- filter(qcData, grepl("PASS", Details)) 

# Convert the rows into string and store on a list to use for filtering org data
databasePassList <- as.character(databasePass$Database)
str(databasePassList)

# Filter org data using generated list
orgPass <- orgData[orgData$V1 %in% databasePassList,] 

# Convert format from long to wide
orgPassWide <- orgPass %>% pivot_wider(names_from = "V1", values_from = "V3")

# Convert tibble to data frame and assign column 1 as rowname
orgPassWide <- as.data.frame(orgPassWide)
rownames(orgPassWide) <- orgPassWide[,1]
orgPassWide <- orgPassWide[,-1]

orgPassWide[1:10,1:6]

# Remove unneeded data
remove(orgPass)
remove(databasePass)
remove(qcSummary)
remove(totalSummary)
remove(qcWarn)
remove(totalWarn)
remove(qcFail)
remove(totalFail)

```

### 5. Aggregate multiple runs, if any, (SRR) to its corresponding experiment (SRX) with PASS only databases

```{r, SRR to SRX Aggregation, echo=TRUE}

# Download and read Metadata summary

if (!file.exists("hsapiens_metadata.tsv.cut")){
    download.file("http://ziemann-lab.net/public/cas/rand/hsapiens_metadata.tsv.cut", 
              destfile = "hsapiens_metadata.tsv.cut")}
    
orgMetadata <- read.csv("hsapiens_metadata.tsv.cut", sep = '\t')

# Filter metadata to include only "passed" samples
orgMetadataPass <- orgMetadata[which(orgMetadata$SRR_accession %in% databasePassList),]

# Assign column 1 as rownames 
rownames(orgMetadataPass) <- orgMetadataPass[,1]
orgMetadataPass <- orgMetadataPass[,-1]

# Put the filtered org GeneCount data and the filtered metadata dataframes into a list
orgCountMetadata <- list(GeneCounts = orgPassWide, MetadataSummary = orgMetadataPass)

# Apply both dataframes to the function
head(orgCountMetadata)
agg <- srx_agg(orgCountMetadata)

# Remove genes with zero total counts 
length(which(rowSums(agg) == 0)) # 83
no_gene_counts <- names(which(rowSums(agg) == 0))

agg <- agg[!(rownames(agg) %in% no_gene_counts),]

# Save agg object
saveRDS(agg, "agg.rds")

# Histogram showing samples (columns) counts
hist(colSums(agg), breaks = 20)

# Remove unneeded data
remove(orgMetadata)

```

### 6. Normalisation of Data (with PASS only databases)

```{r, normalisation, echo=TRUE}

# Filtering low counts
# Check if there are genes with no counts (rowSums==0)
length(which(rowSums(agg) == 0)) # no rowSums = 0

#NORMALISATION FOR COMPOSITION BIAS (TMM normalisation)
dgeObj <- DGEList(agg)
# Apply TMM normalisation to DGEList object
dgeObj <- calcNormFactors(dgeObj, method = "TMM") 
normAgg <- cpm(dgeObj)

# Scale after normalisation
normAggScale <- scale(normAgg)

# Check distributions of samples
hist(normAggScale)
saveRDS(normAggScale,"normAggScale.rds")

# Correlation Matrix
correlate <- cor(t(normAggScale), method = "spearman")
correlate[upper.tri(correlate,diag=TRUE)] <- NA

correlate_melt <- melt(correlate, na.rm = TRUE)

png("Data/hist_vds.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
hist(correlate, breaks = 20, xlab = "Gene Correlation Values", main = "Spearman Correlation of RNASeq Counts")
dev.off()

# Check for 0 values
length(which(correlate_melt$value ==0 )) # no zero values

```

### 7a. Hierarchical Clustering: linking method

There are different ways of deciding the distance of elements for them to be grouped into a cluster.The correlation between the distance matrix and the cophenetic distance is calculated to to ensure good
linkage method fit. 

```{r, hierarchical_clustering, echo=TRUE}

set.seed(42)

distClust <-as.dist(1-cor(t(normAggScale), method="spearman"))
hClust <- hclust(distClust , method="complete")

# Check the correlation between the distance 
# matrix and the cophenetic distance
cophenetic.d = cophenetic(hClust)
correlate_distClustVcoph <- cor(distClust, cophenetic.d)

png("Data/dendro_Average.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
dend <- as.dendrogram(hClust)
#labels_colors(dend) <- "white"
plot(dend, main = paste0("Complete Method: Corr = ", signif(correlate_distClustVcoph)))
dev.off()

```

### 7a.2 Data Removal

Removes data functions for memory storage

```{r, data_removal1, echo=FALSE}

remove(cophenetic.d)
remove(correlate_distClustVcoph)
remove(dend)

```

### 7b. Heirarchical Clustering: deciding the number of clusters
A specific number of clusters can be set using the cutree function.

```{r, heirarchical1, echo=TRUE}

# Using the argument k in cutree is a faster process vs
# figuring out the cut height
  cutClust <- cutree(hClust, k=200)
  cutClustlength <- length(unique(cutClust))
# Cluster size
  cutClustlength
# This is the base code used in the cl_lengthCut function below
  clusters <- as.data.frame(cutClust)
  colnames(clusters) <- "ClusterNumber"
  clusters$GeneID <- rownames(clusters)
  

```

### 8. Clustering genes using different cluster sizes

This functions will will yield a list of genes grouped in cluster sized of 50 to 2000 to be used in downstream processes. Creates the dynamic cluster sizes for the cluster list used in ImputationBlinded and ClustersWithGO stages.
#leave eval=FALSE, code runs with difficulty (requires manual cutHeight addition)

```{r, clustering1, eval=FALSE, include=FALSE}

# Different Cluster sizes using the normal dendrogram cutree function
cutClustvalues <- cl_lengthCut(hClust=hClust, min=50, max=2000, interval=2)
saveRDS(cutClustvalues, "cutClustvalues.rds")

# Different Cluster sizes using the dynamic method, cutreeHybrid from the dynamicTreeCut library
cutClustvalues_dynamic <- cl_cut_dynamic(hClust=hClust, distClust=distClust, min=4, max=302, interval=2)
saveRDS(cutClustvalues_dynamic, "cutClustvalues_dynamic.rds")

```


### 9. Heatmaps for the clusters

NOT WORKING

```{r, heatmaps1, eval=FALSE, include=FALSE}

# # Visualizations
# if (!exists("P100")){
#   P100 <- createPalette(100,  c("#ff0000", "#00ff00", "#0000ff"))}
# 
# clusterCols <- P100[1:100]
# colfunc <- colorRampPalette(c("blue", "white", "red"))
# 
# # Heatmaps TMM
# png("Data/hm_TMM_sp.png", width = 5*300, height = 5*300, res = 300, pointsize = 8)
# cutClustusterSideBar <- clusterCols[normAggCL_sp[["cutClust"]]]
# heatmap.2(corr, main="Gene Correlation (TMM, Spearman)",  Rowv=as.dendrogram(hr),
#           dendrogram="both", scale="col", col = colfunc(25), trace="none",
#           RowSideColors= cutClustusterSideBar, margins = c(5,5))
# dev.off()

```

### 10. Gene Ontology and Gene Data 

A binary matrix was constructed with the Entrez Gene IDs (NCBI gene IDs) as rownames and GO
IDs as the column names (wide format).
If a GO ID is associated with a Gene ID, the cell will equal to 1, otherwise it will be zero. 

Location for downloads: http://current.geneontology.org/products/pages/downloads.html

That database is a bit shit because it doesn't use the ENS gene identfier.

Will investigate using Ensembl BioMart.

```{r, gene_ontol1}

# biomart
ensembl <- useEnsembl(biomart = "genes", dataset = "hsapiens_gene_ensembl")

orgGOlong <- getBM(
  attributes=c("ensembl_gene_id","go_id"), 
  mart = ensembl)

orgGOlong <- orgGOlong[which(orgGOlong$go_id !="" ),]

# GO presence absence matrix
# gene ids in first column
# each row represents a gene (ENSG ID)
# each column represents a GO term eg GO:000002
orgGOmatrixwide <- cbind(orgGOlong[1], mtabulate(as.data.frame(t(orgGOlong[-1]))))

# Save the dataframe to an RDS file
saveRDS(orgGOmatrixwide, "orgGOmatrixwide.rds")

# GeneIDs that are in the gene count data but not in the GO matrix
diffCountGO <- setdiff(rownames(agg), orgGOmatrixwide$GeneID)

# GeneIDs that are in the GO matrix but not in the  gene count data
diffGOCount <- setdiff(orgGOmatrixwide$GeneID, rownames(agg))

# Remove the GeneIDs that are in the GO matrix but not in the gene count data
IndexRemoved <- which(orgGOmatrixwide$GeneID %in% diffGOCount)
GOtable <- orgGOmatrixwide
GOtable <- GOtable[-IndexRemoved,]
# Check if the genes were properly removed 
diffGOCount2 <- setdiff(GOtable$GeneID, rownames(agg))
dim(diffGOCount2)

# Save the new GO table
saveRDS(GOtable, "GOtable.rds")

# Remove unneeded data
remove(orgGOlong)

```

### 11. Blind GO Terms (90-10 split)

10 per cent of GeneIDs will have zero Gene Ontology Annotations. This will serve as the training data.
After the model has been optimised, these IDs will be unblided as the testing data.

```{r, blind_terms, echo=TRUE}

#Fraction of the total number of genes to be blinded
test_size <- floor(0.10 * nrow(GOtable))

## set the seed to make your partition reproducible
set.seed(42)
blinded_ind <- sample(seq_len(nrow(GOtable)), size = test_size)
GOtrain <- GOtable
GOtrain[blinded_ind, 2:ncol(GOtrain)] = 0

saveRDS(GOtrain, "GOtrain.rds")

GO_test <- GOtable[blinded_ind,]
saveRDS(GO_test, "GO_test.rds")
normAggScale_test <- normAggScale[rownames(normAggScale) %in% GO_test$GeneID,]
saveRDS(normAggScale_test, "normAggScale_test.rds")

```

### 12. Data removal

```{r, data_removal2, echo=FALSE}

remove(orgData)

```

### Mem usage

```{r,memusage}

sort( sapply( ls() , function(x) { object.size( get( x ) ) }  )  )

```

### Session Information 

```{r Session Info, echo=FALSE}

sessionInfo()

```
